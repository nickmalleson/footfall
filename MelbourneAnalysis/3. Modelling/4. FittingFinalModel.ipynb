{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the final model\n",
    "<u>Tests using the following models :</u>\n",
    "* Linear regression\n",
    "* Random forest regressor\n",
    "* Ridge and Lasso Regularization (add on to linear modelling?)\n",
    "\n",
    "<u> Tests using the following variables:</u>\n",
    "* Weather variables (rain, temperature, windspeed)\n",
    "* Time variables (Day of week, month, year, time of day, public holiday)\n",
    "* Sensor environment variables:\n",
    "    * Sensor_id\n",
    "    * Betweenness of the street \n",
    "    * Buildings in proximity to the sensor\n",
    "    * Landmarks in proximity to the sensor  \n",
    "    * Furniture in proximity to the sensor    \n",
    "    * Lights in proximity to the sensor   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, mean_squared_error,r2_score, accuracy_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time as thetime\n",
    "from sklearn.model_selection import cross_validate\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from time import time\n",
    "from sklearn.inspection import permutation_importance\n",
    "from scipy import stats\n",
    "\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from Functions import *\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size_m=400\n",
    "input_csv =\"../Cleaned_data/FormattedDataForModelling/formatted_data_for_modelling_allsensors_{}.csv\".format(buffer_size_m)\n",
    "Xfull, Yfull,data_time_columns = prepare_x_y_data(input_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose which month_num and weekday_num option to include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using the dummy variables\n",
    "# Xfull.drop(['Cos_month_num', 'Sin_month_num', 'Cos_weekday_num', 'Sin_weekday_num'], axis=1)\n",
    "# If using the cyclical variables\n",
    "Xfull.drop(['Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday',\n",
    "       'month_2', 'month_3', 'month_4', 'month_5', 'month_6', 'month_7',\n",
    "       'month_8', 'month_9', 'month_10', 'month_11', 'month_12'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'Temp', 'Humidity', 'Pressure', 'Rain', 'WindSpeed',\n",
       "       'Rainfall amount (millimetres)', 'public_holiday', 'school_holiday',\n",
       "       'betweenness', 'lights', 'memorials', 'trees', 'transport_stops',\n",
       "       'bus-stops', 'tram-stops', 'metro-stations', 'taxi-ranks',\n",
       "       'big-car-parks', 'street_inf_Bicycle Rails', 'street_inf_Bollard',\n",
       "       'street_inf_Drinking Fountain', 'street_inf_Floral Crate/Planter Box',\n",
       "       'street_inf_Horse Trough', 'street_inf_Information Pillar',\n",
       "       'street_inf_Litter Bin', 'street_inf_Seat', 'street_inf_Tree Guard',\n",
       "       'landmarks_Community Use', 'landmarks_Mixed Use',\n",
       "       'landmarks_Place Of Assembly', 'landmarks_Place of Worship',\n",
       "       'landmarks_Retail', 'landmarks_Transport', 'landmarks_Education Centre',\n",
       "       'landmarks_Office', 'street_inf_Hoop', 'street_inf_Picnic Setting',\n",
       "       'landmarks_Leisure/Recreation', 'street_inf_Barbeque',\n",
       "       'landmarks_Specialist Residential Accommodation',\n",
       "       'landmarks_Vacant Land', 'landmarks_Purpose Built',\n",
       "       'landmarks_Health Services', 'avg_n_floors', 'buildings_Community Use',\n",
       "       'buildings_Education', 'buildings_Entertainment', 'buildings_Events',\n",
       "       'buildings_Hospital/Clinic', 'buildings_Office', 'buildings_Parking',\n",
       "       'buildings_Residential', 'buildings_Retail', 'buildings_Storage',\n",
       "       'buildings_Unoccupied', 'buildings_Working',\n",
       "       'buildings_Public Display Area', 'buildings_Transport', 'Sin_time',\n",
       "       'Cos_time', 'Sin_month_num', 'Cos_month_num', 'Sin_weekday_num',\n",
       "       'Cos_weekday_num', 'distance_from_centre', 'random', 'random_cat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xfull.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the final model\n",
    "Random Forest with a buffer size of 500m was the best performing model from CV  \n",
    "For this, we use all of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving pickled file\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Results/FinalModels/rf_model_pipeline1_400.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the final model\n",
    "rf_model_pipeline1 = Pipeline(steps=[['scaler',StandardScaler()],\n",
    "                                    ['rf_regressor',RandomForestRegressor(random_state = 1, n_jobs = 32)]])\n",
    "rf_model_pipeline1.fit(Xfull, Yfull)\n",
    "print(\"saving pickled file\")\n",
    "# Save to pickled file\n",
    "filename = 'Results/FinalModels/rf_model_pipeline1_{}.pkl'.format(buffer_size_m)\n",
    "joblib.dump(rf_model_pipeline1, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving pickled file\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Results/FinalModels/rf_model_pipeline2_400.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the final model\n",
    "rf_model_pipeline2 = Pipeline(steps=[['scaler',StandardScaler()],\n",
    "                                    ['rf_regressor',RandomForestRegressor(random_state = 2, n_jobs = 32)]])\n",
    "rf_model_pipeline2.fit(Xfull, Yfull)\n",
    "print(\"saving pickled file\")\n",
    "# Save to pickled file\n",
    "filename = 'Results/FinalModels/rf_model_pipeline2_{}.pkl'.format(buffer_size_m)\n",
    "joblib.dump(rf_model_pipeline2, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving pickled file\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Results/FinalModels/rf_model_pipeline3_400.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the final model\n",
    "rf_model_pipeline3 = Pipeline(steps=[['scaler',StandardScaler()],\n",
    "                                    ['rf_regressor',RandomForestRegressor(random_state = 2, n_jobs = 32)]])\n",
    "rf_model_pipeline3.fit(Xfull, Yfull)\n",
    "print(\"saving pickled file\")\n",
    "# Save to pickled file\n",
    "filename = 'Results/FinalModels/rf_model_pipeline3_{}.pkl'.format(buffer_size_m)\n",
    "joblib.dump(rf_model_pipeline3, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xfull.to_csv('Results/FinalModels/Xfull_rf_model_pipeline1_{}.csv'.format(buffer_size_m), index=False)\n",
    "Yfull_df=pd.DataFrame(Yfull)\n",
    "Yfull_df.to_csv('Results/FinalModels/Yfull_rf_model_pipeline1_{}.csv'.format(buffer_size_m), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Xfull.columns)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
